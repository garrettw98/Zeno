# Chapter 20
## The Tiered Transparency Framework

---

In February 2025, a coalition of AI researchers, civil liberties groups, and governance experts published an open letter: the Open Source AI Framework (O-SAIF). Their argument was simple but radical:

Government AI must be open source. No exceptions.

The signatories included people who had worked at major AI labs, who understood the technology deeply, who knew both its potential and its risks. They were not anti-technology activists but believers that technology should serve democratic values.

Their core argument: you cannot have democratic control over systems you cannot examine. If government AI is a black box—if citizens cannot see how decisions are made—then democracy is replaced by technocracy. The officials become those who control the code, and everyone else becomes subject to algorithms they can neither understand nor challenge.

The Human Standard adopts this argument entirely. Open source is not a preference. It is a mandate.

---

### The Case for Openness

Why must government AI be open source? Several arguments reinforce each other:

**Democratic accountability**: In a democracy, citizens have the right to know how their government works. This is not an abstract principle but a practical requirement. If we cannot see the rules by which we are governed, we cannot evaluate whether those rules are just.

Government AI makes decisions—about benefits, licenses, enforcement, allocation. These decisions affect lives. Citizens must be able to understand why a decision was made, challenge decisions they believe are wrong, and change the rules through democratic process.

Closed-source AI defeats all of this. The logic is hidden. Challenges are impossible because the basis for decisions is unknown. Changing rules requires access that only the system's owners have.

**Security through transparency**: The intuition that secrecy increases security is often wrong. Closed systems hide vulnerabilities that attackers can discover while defenders remain ignorant. Open systems allow many eyes to find vulnerabilities, fix them, and improve security.

This is not theoretical. The most secure software systems tend to be open source—Linux, OpenSSL, many others. The security community has repeatedly demonstrated that secrecy creates a false sense of security while openness creates actual security.

For government AI, the stakes are highest. These systems affect millions of people. They must be as secure as possible. Open source achieves security better than closed systems.

**Preventing capture**: Closed-source systems are vulnerable to capture by their developers. If only one company understands how the system works, that company gains enormous power over government. They can embed advantages, create dependencies, and extract rents.

Open source prevents this capture. No single company owns the code. Development can continue regardless of any company's decisions. Competition ensures government is not held hostage by proprietary technology.

**Quality improvement**: Open source enables distributed improvement. Researchers worldwide can examine code, identify problems, propose solutions. The collective intelligence of the open-source community exceeds what any closed development team can achieve.

Government AI should benefit from this collective intelligence. Problems should be found before they cause harm. Improvements should come from wherever they originate. Closed systems forgo these benefits.

**Trust**: Perhaps most fundamentally, open source enables trust. Citizens can verify that systems do what they claim to do. Independent experts can validate that AI is not biased, not manipulated, not serving hidden interests.

In an era of declining institutional trust, this verification capacity is essential. "Trust but verify" requires the capacity to verify. Open source provides it.

---

### The Prohibition

The Human Standard prohibits closed-source AI for government administrative decisions.

This means:

- No proprietary AI systems making decisions about benefits, enforcement, licensing, procurement, or resource allocation
- No contracts with AI vendors that require code secrecy
- No government-developed AI that is not published for public review
- No "commercial confidentiality" exceptions for AI decision systems

The prohibition applies to all levels of government: federal, state, and local. It applies to contractors and grantees who perform government functions. It applies regardless of efficiency arguments or cost considerations.

This is an absolute requirement, not a preference to be weighed against other factors.

---

### The National AI Repository

Open source requires infrastructure. The Human Standard proposes a National AI Repository.

**Function**: A curated, secure, publicly accessible collection of government AI systems.

**Contents**:
- All code for government AI systems
- Training data documentation (not necessarily raw data where privacy concerns exist)
- Model architectures and parameters
- Testing results and audit reports
- Documentation for understanding and modification

**Management**:
- Independent agency with technical expertise
- Insulated from political pressure
- Transparent operations and governance

**Access**:
- Full public access for reading and review
- Contribution mechanisms for improvements
- Version control tracking all changes
- Clear licensing for permissible uses

**Security**:
- Vulnerability disclosure process
- Rapid response to identified problems
- Security review for all contributions
- Protection against malicious modifications

The Repository makes the open-source mandate practical. Citizens do not need to request code under FOIA; it is available by default. Researchers do not need special access; the Repository provides it.

---

### Addressing Concerns

The open-source mandate faces predictable objections:

**"Open source is less secure"**: This is backwards. Security research consistently shows that open systems are more secure than closed systems. "Security through obscurity" is a discredited approach. Open review catches vulnerabilities; closed development hides them.

For government AI specifically, the risk of hidden manipulation far exceeds the risk of examined code. We should be more worried about AI that cannot be checked than about AI that many people examine.

**"Open source enables gaming"**: If people can see the rules, won't they game them? Perhaps—but gaming is already endemic in opaque systems, and harder to detect. Open rules can be designed to resist gaming; closed rules cannot be democratically evaluated at all.

Moreover, the alternative to gaming open rules is not ungamed closed rules—it is corrupt closed rules that benefit insiders. Gaming by citizens is more democratic than manipulation by elites.

**"Proprietary systems are better"**: Some argue that closed development produces superior AI. The evidence is mixed, but even if true, the appropriate response is not to abandon openness but to invest in open-source development.

Government can fund open AI research. It can mandate that government contractors release code. It can create incentives for private open-source development. The goal is excellent open AI, not acceptance of inferior open AI.

**"This will slow deployment"**: Perhaps. But fast deployment of unaccountable AI is worse than slower deployment of accountable AI. Government should prioritize getting AI right, not getting it fast.

---

### Data Sovereignty

Open-source code is necessary but not sufficient. Data also matters.

Government AI systems use data about citizens. This data must be:

**Protected**: Encryption by default. Access controls. Audit logging of all data access. Protection from unauthorized disclosure.

**Citizen-owned**: Data about you belongs to you. Government holds it as a trustee, not an owner. You can access your data, correct errors, and understand how it is used.

**Minimized**: Government collects only data necessary for legitimate purposes. Data is deleted when no longer needed. Collection is transparent and justified.

**Non-commercial**: Government data is not sold or shared for commercial purposes. It is not a revenue source. It serves public functions only.

**Portable**: Citizens can export their data in standard formats. They are not locked into government systems. Data follows them.

These principles apply to both human-administered and AI-administered government. But AI systems intensify the need—they can process more data, identify more patterns, create more comprehensive profiles. Stronger protections are necessary.

---

### The Developer Community

Open source is not just a publication requirement. It is an invitation to participate.

Government AI should benefit from:

**Bug bounties**: Reward researchers who find vulnerabilities. Create incentives for security improvement.

**Feature proposals**: Allow community suggestions for improvements. Evaluate proposals on merit, not origin.

**Quality contributions**: Accept code contributions that pass review. The government does not have a monopoly on good ideas.

**Diverse perspectives**: Open development includes voices that closed development excludes. Bias is more likely to be caught when many perspectives examine the code.

**Academic research**: Universities can study government AI, publish findings, and improve practice. This contributes to collective understanding.

The developer community becomes a national asset—thousands of people improving government systems out of civic commitment, professional interest, or both.

---

### International Implications

Open-source government AI has international implications:

**Leadership**: If America develops excellent open-source AI for government, other democracies can adopt and adapt it. American development becomes global infrastructure for democratic governance.

**Contrast**: Closed authoritarian AI (like China's social credit system) contrasts with open democratic AI. The difference becomes visible—transparency versus opacity, accountability versus control.

**Standards**: American open-source practices can become international standards. Other countries adopting algorithmic government can build on American work.

**Security**: Open-source AI is harder to compromise through supply chain attacks. International adversaries cannot embed hidden capabilities in code that everyone can examine.

This is soft power through technology—demonstrating that democratic governance can be more effective and more trustworthy than authoritarian alternatives.

---

### The Implementation Path

Implementing the open-source mandate requires:

**Phase 1 (2025-2027): Inventory and Evaluation**

- Catalog all existing government AI systems
- Evaluate each for open-source feasibility
- Begin publishing code for systems without security concerns
- Develop transition plans for proprietary systems

**Phase 2 (2027-2029): Transition**

- New AI systems must be open source from inception
- Existing systems transition to open source on defined timelines
- Build National AI Repository infrastructure
- Develop contributor community

**Phase 3 (2029-2031): Full Implementation**

- Civilian government AI under Tiered Transparency Framework
- Repository fully operational
- Active contributor community
- Regular audit and improvement processes

**Phase 4 (2031+): Mature System**

- Open source is default assumption
- Continuous improvement through community contribution
- International adoption of American open-source systems
- Regular review and enhancement

The timeline is aggressive but achievable. The mandate is clear: closed-source government AI will end.

---

### The Broader Principle

The open-source mandate reflects a broader principle: transparency is the price of power.

Government has enormous power over citizens. That power is justified only if it can be examined, understood, and challenged. Opacity in government is not a neutral feature—it is a shift of power away from citizens and toward those who control the opaque systems.

AI intensifies this dynamic. Automated decisions affect millions. If those decisions cannot be examined, citizens are governed by systems they cannot understand or challenge. This is incompatible with democracy.

Open source is the democratic response. Power remains with citizens because citizens can see how power is exercised. Accountability is real because the basis for decisions is visible. Trust is possible because verification is possible.

This is not anti-technology. It is pro-democracy technology—technology designed to serve democratic values rather than undermine them.

The Human Standard makes this explicit. Government AI serves citizens. Citizens can examine how it serves them. This is not negotiable.

---

*Next: Chapter 21 - The Algorithmic Government*
